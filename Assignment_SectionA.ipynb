{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "1meWQb0hT8MO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# check if this instance of the notebook already has files present\n",
        "# and thus determine which steps required prior to reading in file and handling the data\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "IfUDk8dj-iuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40ZMzK1NEOxG",
        "collapsed": true
      },
      "source": [
        "# set-up spark (NB if Apache amend versions on download site we will need to amend path in wget command)\n",
        "## NOTE that this version would make use of Hadoop if installed BUT that HDFS & Hadoop is not installed on our Colab\n",
        "## (we are only using a single node (probably as a VM) so we will not be able to benefit from parallelism)\n",
        "!clear\n",
        "!echo welcome\n",
        "\n",
        "!rm -f spark-3.4.[01]-bin-hadoop3.tgz*\n",
        "!rm -rf spark-3.4.[01]-bin-hadoop3\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.4.4/spark-3.4.4-bin-hadoop3.tgz\n",
        "!tar -xf spark-3.4.4-bin-hadoop3.tgz\n",
        "\n",
        "!ls -alt\n",
        "print(\"standalone Spark is now installed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZguLonUE-js",
        "collapsed": true
      },
      "source": [
        "# init spark (ensure SPARK_HOME set to same version as we download earlier)\n",
        "!pip3 install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.4-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkConf, SparkContext\n",
        "# the next line gives us 'local' mode. try 'local[2]' to use 2 cores or 'master:NNNN' to run on Spark standalone cluster at port NNNN\n",
        "spark_conf = SparkConf().setMaster('local[2]').setAppName('MyApp')\n",
        "sc = SparkContext(conf=spark_conf)\n",
        "# see what we have by examining the Spark User Interface\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "SparkSession.builder.getOrCreate()\n",
        "##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io"
      ],
      "metadata": {
        "id": "8cBu5gPsk9ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABQESgtdFZxa"
      },
      "source": [
        "## this is how one could upload a file into colab using the colab GUI (uncomment both lines if want to try it)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "zQJKj6dtw_mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Big_Data_Assignment_Dataset.zip"
      ],
      "metadata": {
        "id": "8VDNXJK3m6wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# at this point we have Spark initialised and we have a number of CSV files.\n",
        "# NB you can try also download the zipfile to your host machine and try opening in Excel (Win)\n",
        "# (in Linux, easiest to open a file manager GUI then double-click on .csv file to open associated spreadsheet app)"
      ],
      "metadata": {
        "id": "wgH7CS0VBLPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ùì ‚Äî Question:\n",
        "##1Ô∏è‚É£Step 1:\n",
        "- Based on your lectures and labs, your Research Hypothesis is: ‚ÄúIn the second quarter of 2014, products given\n",
        "a review rating of 3 or more are significantly different compared to other products‚Äù which you may refine to make more precise and/or testable from the data available in the provided dataset. You should only use the provided dataset for the Hypothesis.\n",
        "\n",
        "## 2Ô∏è‚É£Step 2:\n",
        "- Write your report where, for the above Research Hypothesis, in a clear, concise and consistent\n",
        "manner, you should not exceed 1000 words and:\n",
        "  - include a title page giving your name, MMU ID, signed declaration the work is your own\n",
        "  -state the Research Hypothesis and your test for determination of whether it is true\n",
        "  -explain the results and discuss your approach and what you have learned from the data\n",
        "  *detail your test on the required data and state whether the Hypothesis has been found true or not, or what you would need to do next to obtain a conclusive result\n",
        "\n",
        "## 3Ô∏è‚É£ Step 3:\n",
        "- End-to-End Big Data Pipeline - This section should not exceed 500 words for the technical report. This section\n",
        "assesses your competency with the core big data tools and your ability to integrate them into an end-to\u0002end pipeline.\n",
        "- You have been given a public dataset (or you may choose one of your own from a reputable open data\n",
        "source). Your task is to design and implement a big data pipeline that showcases your understanding of\n",
        "the following technologies within your Azure Labs environment or Google Colab if you prefer:\n",
        "  1. Hadoop (HDFS) ‚Äì for distributed data storage.\n",
        "  2. Spark ‚Äì for data processing or a machine learning task (Spark MLlib).\n",
        "  3. Kafka ‚Äì for streaming data ingestion (can be real or simulated).\n",
        "  4. Scala ‚Äì as the programming language for your Spark and Kafka integration code\n",
        "  5. Data Source: Pick a public dataset. For instance:\n",
        "    - (a). OpenWeather API for streaming weather data, or\n",
        "    - (b). Mockaroo-generated data"
      ],
      "metadata": {
        "id": "t2_HFtZZLVyp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmIQqnIFGKKl"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"electronics_ratings\").getOrCreate()\n",
        "file = \"./ratings_Electronics (1).csv\"\n",
        "column_names = [\"userID\", \"productID\", \"Rating\", \"timestamp\"]\n",
        "# Read the CSV file\n",
        "df = (spark.read.format(\"csv\")\n",
        "         .option(\"header\", \"true\")\n",
        "         .option(\"inferSchema\", \"true\")\n",
        "         .load(file)\n",
        "         .toDF(*column_names))\n",
        "\n",
        "# Show the top 10 rows\n",
        "df.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df = df.withColumn(\"datetime\", from_unixtime(col(\"timestamp\")).cast(\"timestamp\"))\n"
      ],
      "metadata": {
        "id": "9_bC7s6i1GA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "id": "4fflzowGrD_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking at the shape of the dataset"
      ],
      "metadata": {
        "id": "YIYR5EYa-L9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = df.count()\n",
        "num_cols = len(df.columns)\n",
        "print((num_rows, num_cols))\n"
      ],
      "metadata": {
        "id": "TQQz-PItrsII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîç Finding the üëØDuplicates"
      ],
      "metadata": {
        "id": "k8_Jl5Yg-HNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "num_duplicates = (\n",
        "    df.groupBy(df.columns)\n",
        "      .count()\n",
        "      .filter(\"count > 1\")\n",
        "      .agg(F.sum(F.col(\"count\") - 1).alias(\"total_duplicates\"))\n",
        "      .collect()[0][\"total_duplicates\"]\n",
        ")\n",
        "\n",
        "print(f\"üî¢ Total number of duplicate rows: {num_duplicates or 0}\")\n"
      ],
      "metadata": {
        "id": "2eMmByuC75FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # üìù Conclusion:\n",
        " As there is no duplicates meaning that the each product has one rating and one time stamp\n"
      ],
      "metadata": {
        "id": "5PsW4FFsKqdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö†Ô∏è Looking at the Null values"
      ],
      "metadata": {
        "id": "d0g0ybok-cwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, when\n",
        "\n",
        "df.select([\n",
        "    sum(when(col(c).isNull(), 1).otherwise(0)).alias(c + \"_nulls\")\n",
        "    for c in df.columns\n",
        "]).show()\n",
        "\n",
        "print(\"‚ö†Ô∏è Features with Null Values:\")\n"
      ],
      "metadata": {
        "id": "MUwckIDx9MBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dividing the datetime into date and time colomn\n"
      ],
      "metadata": {
        "id": "QL71eLpUBb9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df = df.withColumn(\"date\", F.split(F.col(\"datetime\"), \" \").getItem(0)) \\\n",
        "             .withColumn(\"time\", F.split(F.col(\"datetime\"), \" \").getItem(1)) \\\n",
        "             .drop(\"datetime\")\n",
        "df.show(10)"
      ],
      "metadata": {
        "id": "2sRSD2dsBhJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "id": "61MdqSGmF9yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Important Insights from (<font color=\"yellow\">Descriptive Stats Table</font>)\n",
        "\n",
        "\n",
        "1.   the data is from 1998-12-04 to 2014-07-23\n",
        "2.   the mean value of rating is 4.012 and the std of rating 1.38\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1y-cZMvG8lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßë‚Äçüíª Checking Data Types of Features:"
      ],
      "metadata": {
        "id": "1meWQb0hT8MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data types of each column in the DataFrame\n",
        "df.dtypes\n"
      ],
      "metadata": {
        "id": "beB-cW1WT2NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Filtering the data for second Quarter (<font color=\"#FF5733\">April 1 to June 30</font>) of 2014\n"
      ],
      "metadata": {
        "id": "xyysTa4XN2Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "# converting string datatype of date into date type\n",
        "df = df.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "# Select the desired columns\n",
        "df_1 = df.select(\"productId\", \"Rating\", \"date\")\n",
        "df_1.show()\n",
        "\n",
        "# here to_date converts the datatype string to date format\n",
        "\n",
        "# Filter the DataFrame for Q2 2014 (April to June 2014)\n",
        "fil_df = df_1.filter((col(\"date\") >= '2014-04-01') & (col(\"date\") <= '2014-06-30'))\n",
        "# the filter method is used to filter out the desired second quarter of 2014\n",
        "fil_df.show()"
      ],
      "metadata": {
        "id": "pCZ9GridNlW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fil_df.describe().show()"
      ],
      "metadata": {
        "id": "xciclUB3IXXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fil_df.dtypes"
      ],
      "metadata": {
        "id": "cOWJ5dMsWKqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = fil_df.count()\n",
        "num_cols = len(fil_df.columns)\n",
        "print((num_rows, num_cols))\n"
      ],
      "metadata": {
        "id": "EmxlTICvWAa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìùNote:\n",
        "- at start they were (7824481, 5)\n",
        "- now after filtering they are (664014, 3)\n",
        "- 7,160,467 are are the datapoint other than our required hypothesis points.\n",
        "\n"
      ],
      "metadata": {
        "id": "ToGCbJNoXrCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Two Groups:\n",
        "    Rating Category:\n",
        "    - High for >=3\n",
        "    - Low for <3"
      ],
      "metadata": {
        "id": "gGcIlZocgHRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "fil_df = fil_df.withColumn(\n",
        "    \"rating_category\",\n",
        "    when(fil_df[\"Rating\"] >= 3, \"High\").otherwise(\"Low\")\n",
        ")\n",
        "\n",
        "fil_df.show()"
      ],
      "metadata": {
        "id": "qMKJwhMlXpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_high = fil_df[fil_df['rating_category'] == 'High']\n",
        "group_low = fil_df[fil_df['rating_category'] == 'Low']\n"
      ],
      "metadata": {
        "id": "cKalQsaNipdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fil_df.groupBy(\"rating_category\").count().show()\n"
      ],
      "metadata": {
        "id": "5hVWlovJi64Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion/Insights:\n",
        "- The numberof high rated rating in Q2 2014 are 549939\n",
        "- the number of low rating products in Q2 2014 are 114075"
      ],
      "metadata": {
        "id": "Bnd1yENOkFHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution graph"
      ],
      "metadata": {
        "id": "kijaqmpIkic6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of each rating (e.g., 1-5)\n",
        "rating_counts = fil_df.groupBy(\"Rating\").count().orderBy(\"Rating\")\n",
        "\n",
        "# Now convert the small aggregated result to Pandas\n",
        "rating_counts_pd = rating_counts.toPandas()\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Rating\", y=\"count\", data=rating_counts_pd, palette=\"viridis\")\n",
        "plt.title(\"Rating Distribution\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-DMYJAA9mTic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # üìù Conclusion:\n",
        "-  The higher frequency are of high 5 in rating then 4.\n",
        "-  The  data is left skewed as we can see becaus of the high rated 5 which moved the mean to right side as we can see from descriptive stats. .\n",
        "-  This should be noted that the graph is about the filtered data which is of Q2 2014"
      ],
      "metadata": {
        "id": "AnYM-M7opoH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Aggregate or select the 'Rating' column\n",
        "rating_df = fil_df.select(\"Rating\")\n",
        "\n",
        "# 3. Convert to Pandas (works well for small columns like this)\n",
        "rating_pd = rating_df.toPandas()\n",
        "\n",
        "# 4. Plot the distribution using seaborn or matplotlib\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(rating_pd['Rating'], bins=5, kde=True, color='skyblue')\n",
        "plt.title(\"Distribution of Product Ratings in Q2 2014\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0tqCVu82kEa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'productid' and count the number of ratings for each product\n",
        "rating_count_df = fil_df.groupBy(\"productid\").count()\n",
        "\n",
        "# Filter the products with more than one rating\n",
        "products_with_multiple_ratings = rating_count_df.filter(col(\"count\") > 1)\n",
        "\n",
        "# Show the result\n",
        "products_with_multiple_ratings.show()"
      ],
      "metadata": {
        "id": "M_wNRVKx56dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 2. Calculate average rating per product"
      ],
      "metadata": {
        "id": "l1lzgsDrK5Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_ratings = fil_df.groupBy(\"productId\").agg(avg(\"Rating\").alias(\"avg_rating\"))\n",
        "print(avg_ratings.show())"
      ],
      "metadata": {
        "id": "gWmaUmId31SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This means that the prodcuts have more than one ratings.\n",
        "- using the average rating will help us to give products with more high ratings."
      ],
      "metadata": {
        "id": "_xeorZHw6aX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 3. Count number of reviews per product"
      ],
      "metadata": {
        "id": "02wtrgVhKxSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_counts = fil_df.groupBy(\"productId\").count().withColumnRenamed(\"count\", \"num_reviews\")\n"
      ],
      "metadata": {
        "id": "CiuvOZhIKrLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 4. Merge average rating and review count"
      ],
      "metadata": {
        "id": "OA9LQbWlK8RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_stats = avg_ratings.join(review_counts, on=\"productId\")\n"
      ],
      "metadata": {
        "id": "CoqK_SAoLBAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 5. Categorize products as high or low rated"
      ],
      "metadata": {
        "id": "0l_P3LLhLNpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_stats = product_stats.withColumn(\"Rating_Category\",\n",
        "    when(col(\"avg_rating\") >= 3, \"high\").otherwise(\"low\"))\n"
      ],
      "metadata": {
        "id": "YQiW8FUQLQkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 6. Compare number of reviews between high-rated and low-rated products"
      ],
      "metadata": {
        "id": "GfvavXmvLuY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you're using Spark and want to do a quick summary:\n",
        "product_stats.groupBy(\"Rating_Category\").agg(avg(\"num_reviews\")).show()\n"
      ],
      "metadata": {
        "id": "i8seVfS8Lvr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_df = product_stats.toPandas()\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "high = pd_df[pd_df['Rating_Category'] == 'high']['num_reviews']\n",
        "low = pd_df[pd_df['Rating_Category'] == 'low']['num_reviews']\n",
        "\n",
        "t_stat, p_val = ttest_ind(high, low, equal_var=False)\n",
        "print(\"p-value:\", p_val)\n",
        "if p_val < 0.05:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in the average number of reviews between high-rated and low-rated products.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in the average number of reviews between high-rated and low-rated products.\")"
      ],
      "metadata": {
        "id": "0Zvo4WDONYDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 7. Interpret the result"
      ],
      "metadata": {
        "id": "Aj6R7NlnNey_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see that p value is less than 0.05 , reject the null hypothesis\n",
        "- There is a significant difference."
      ],
      "metadata": {
        "id": "QZ3CQAkLOXgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üé® 2. Plot the Bar Chart"
      ],
      "metadata": {
        "id": "f1mCBb2SPBJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting the average number of reviews by rating category (high vs low)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x='Rating_Category', y='num_reviews', data=pd_df, estimator='mean', ci=None, palette='coolwarm')\n",
        "\n",
        "plt.title('Average Number of Reviews: High vs Low Ratings (Q2 2014)', fontsize=16)\n",
        "plt.xlabel('Rating Category', fontsize=14)\n",
        "plt.ylabel('Average Number of Reviews', fontsize=14)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PBVKxE54NgJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öñÔ∏è <font color=\"white\">Hypothesis Testing</font>:\n",
        "###- \"Products with ‚â•3-star ratings in Q2 2014 (Apr-Jun 2014) have a significantly higher average number of reviews compared to products with <3-star ratings in the same period.\""
      ],
      "metadata": {
        "id": "KesTVKlaQ1-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üòê H‚ÇÄ (Null Hypothesis):\n",
        "  - There's no significant difference in the average number of reviews between <font color=\"Green\">high-rated products (rating ‚â• 3)</font> and <font color=\"Red\">low-rated products (rating < 3)</font>.\""
      ],
      "metadata": {
        "id": "MJAHpzx3sS5S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42-UOHwr29wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üòÆ H‚ÇÅ (Alternate Hypothesis):\n",
        "- There is a significant difference in the average number of reviews between <font color=\"Green\">high-rated products (rating ‚â• 3)</font> and <font color=\"Red\">low-rated products (rating < 3)</font>."
      ],
      "metadata": {
        "id": "MWTGbhna1EIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ye bhi ho skta hai k 2014 me 3 se upar wlai zda the baki salo se\n",
        "ye bhi ho skta hai k 3 quarter or 1 quarter ko compare kia jai .\n"
      ],
      "metadata": {
        "id": "BDRW65UMaPNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great question! Let's discuss both approaches so you can decide which one is the best fit for your hypothesis.\n",
        "\n",
        "### üß† **Approach 1: Using the Average Number of Reviews**\n",
        "\n",
        "In this approach, you're testing the hypothesis that **products with higher ratings (‚â• 3)** have a **significantly higher number of reviews** compared to those with lower ratings (< 3).\n",
        "\n",
        "- **Strengths of this approach:**\n",
        "  1. **Clear comparison**: You are comparing a measurable metric (number of reviews) directly between two groups (high-rated vs low-rated products).\n",
        "  2. **Real-world relevance**: It makes sense in a business context‚Äîproducts with more positive reviews could indicate better customer satisfaction or higher sales, making it valuable for analysis.\n",
        "  3. **Statistical rigor**: A t-test or similar test works well here, as you‚Äôre comparing the mean review counts of the two groups.\n",
        "\n",
        "- **Challenges:**\n",
        "  1. **Assumption**: This approach assumes the average number of reviews is the best way to represent the \"popularity\" or \"performance\" of a product.\n",
        "  2. **Potential skew**: If a product has just a few reviews but a high rating, it might skew the results. For example, a product with only 3 reviews, all rated 5 stars, might have a higher rating but not be a fair comparison to a product with 100 reviews.\n",
        "\n",
        "### üßë‚Äçüíª **Approach 2: Using the Rating Category Only (without counting reviews)**\n",
        "\n",
        "In this approach, you might look at the **distribution of products based on their rating category**, without considering how many reviews they have. For example:\n",
        "- **Group A (high ratings)**: Products with ratings ‚â• 3\n",
        "- **Group B (low ratings)**: Products with ratings < 3\n",
        "\n",
        "You could then compare these two groups in terms of other variables (like their average rating, the number of products, etc.).\n",
        "\n",
        "- **Strengths of this approach**:\n",
        "  1. **Simpler analysis**: You might focus purely on the rating values and avoid complications from different numbers of reviews.\n",
        "  2. **Direct interpretation**: It's easier to understand whether high-rated products (‚â• 3) differ from low-rated ones in terms of their ratings.\n",
        "  3. **No skew from review counts**: Since you're not looking at the number of reviews, you avoid potential skew from a few very high-rated products with few reviews.\n",
        "\n",
        "- **Challenges**:\n",
        "  1. **Lack of a performance measure**: You're not testing the **effectiveness** or **popularity** of products (which number of reviews could indicate). You would be missing the connection between the **rating** and **review volume**.\n",
        "  2. **Less practical**: In many cases, you'd want to understand whether products with better ratings are actually more popular or reviewed more, which this approach doesn‚Äôt directly measure.\n",
        "\n",
        "### üèÜ **Which approach is best?**\n",
        "\n",
        "**It depends on your research question**:\n",
        "- If you want to explore **whether higher-rated products are getting more attention or reviews**, **Approach 1** (Average Number of Reviews) would likely be the better fit. This approach aligns with your hypothesis and gives a more **complete picture** of how reviews and ratings interact.\n",
        "\n",
        "- If you want a **more basic comparison** and are only interested in comparing product ratings without considering the number of reviews, **Approach 2** (Using Rating Category Only) might be sufficient but might **miss out on a more nuanced analysis**.\n",
        "\n",
        "### üßë‚Äçüè´ **Optimized Approach:**\n",
        "Given that your hypothesis suggests that products with **ratings ‚â• 3** should differ from others in terms of **number of reviews**, **Approach 1** is probably the **best choice**. You will:\n",
        "1. Use **number of reviews** as a performance metric.\n",
        "2. Compare products based on their **rating category** (high vs low).\n",
        "3. Perform a **statistical test** (like a t-test) to see if there's a significant difference in the average number of reviews.\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ **Next Steps:**\n",
        "\n",
        "- **If using Approach 1 (number of reviews)**, you can:\n",
        "  - Test the **average number of reviews** for each group using a **t-test**.\n",
        "  - Visualize the results using a **bar chart** or **box plot**.\n",
        "  \n",
        "- **If you wanted to use Approach 2 (rating category)**, you would compare:\n",
        "  - The **average rating** for each group.\n",
        "  - Maybe calculate how many products fall into each category and look for trends.\n",
        "\n",
        "---\n",
        "\n",
        "### üí° **Summary**:  \n",
        "I recommend **Approach 1** as it provides more detailed insight into whether higher-rated products are reviewed more frequently. This fits well with your hypothesis about **ratings affecting review counts**.\n",
        "\n",
        "Let me know if you'd like help implementing any of these approaches or further refining the analysis!"
      ],
      "metadata": {
        "id": "Q8Fd1RO0QAbr"
      }
    }
  ]
}